{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defined-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_data_loader,build_vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from baseline import init_model\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import math\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "uniform-reform",
=======
   "id": "spiritual-fitness",
>>>>>>> 710f73201b0db08b166e19b2ea10de04eb0fac27
   "metadata": {},
   "source": [
    "## PARSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
<<<<<<< HEAD
   "id": "beautiful-shift",
=======
   "id": "recovered-giant",
>>>>>>> 710f73201b0db08b166e19b2ea10de04eb0fac27
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choice = 'baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
<<<<<<< HEAD
   "id": "correct-bundle",
=======
   "id": "moving-sheriff",
>>>>>>> 710f73201b0db08b166e19b2ea10de04eb0fac27
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_choice == 'baseline':\n",
    "    from baseline import init_model, train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
<<<<<<< HEAD
   "id": "remarkable-cheese",
=======
   "id": "empirical-rehabilitation",
>>>>>>> 710f73201b0db08b166e19b2ea10de04eb0fac27
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time: int,\n",
    "               end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
<<<<<<< HEAD
   "id": "minor-cedar",
=======
   "id": "expired-sherman",
>>>>>>> 710f73201b0db08b166e19b2ea10de04eb0fac27
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_execute(model,train_data,val_data,test_data,criterion,optimizer,clip_value, n_epochs,models_path):\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = train(model, train_data, optimizer, criterion, clip_value)\n",
    "        valid_loss = evaluate(model, val_data, criterion)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "\n",
    "    test_loss = evaluate(model, test_data, criterion)\n",
    "\n",
    "    print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')\n",
    "    \n",
    "    torch.save(model.state_dict(),join(models_path,\"model\" + time.strftime(\"_%d-%m_%H-%M\")))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "continent-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "NL_TOKENIZER = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "QL_TOKENIZER = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "resident-sculpture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required files exist!\n",
      "Model path exists!\n"
     ]
    }
   ],
   "source": [
    "data_path = join(\"..\",\"..\",\"data\",\"eiopa\",\"3_processed\")\n",
    "train_file_nl = join(data_path,\"data_baseline.nl\")\n",
    "train_file_ql = join(data_path,\"data_baseline.ql\")\n",
    "\n",
    "models_path = join(\"..\",\"..\",\"models\")\n",
    "\n",
    "if exists(train_file_nl) and exists(train_file_ql):\n",
    "    print(\"Required files exist!\")\n",
    "    \n",
    "if exists(models_path):\n",
    "    print(\"Model path exists!\")\n",
    "    \n",
    "vocab_nl = build_vocab(train_file_nl,NL_TOKENIZER)\n",
    "\n",
    "vocab_ql = build_vocab(train_file_ql,QL_TOKENIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "clear-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_data_loader(train_file_nl,train_file_ql,vocab_nl,vocab_ql,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pregnant-phone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized! \n",
      " The model has     1,876,371 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model,optimizer = init_model(DEVICE,len(vocab_nl),len(vocab_ql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "norwegian-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = vocab_ql.stoi['<pad>'] # for ouput language\n",
    "CRITERION = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "viral-rhythm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 1m 57s\n",
      "\tTrain Loss: 3.995 | Train PPL:  54.334\n",
      "\t Val. Loss: 3.208 |  Val. PPL:  24.727\n",
      "Epoch: 02 | Time: 1m 52s\n",
      "\tTrain Loss: 2.808 | Train PPL:  16.582\n",
      "\t Val. Loss: 2.651 |  Val. PPL:  14.162\n",
      "Epoch: 03 | Time: 1m 51s\n",
      "\tTrain Loss: 1.935 | Train PPL:   6.924\n",
      "\t Val. Loss: 2.517 |  Val. PPL:  12.395\n",
      "Epoch: 04 | Time: 1m 52s\n",
      "\tTrain Loss: 1.213 | Train PPL:   3.362\n",
      "\t Val. Loss: 2.627 |  Val. PPL:  13.828\n",
      "Epoch: 05 | Time: 1m 50s\n",
      "\tTrain Loss: 0.919 | Train PPL:   2.507\n",
      "\t Val. Loss: 2.983 |  Val. PPL:  19.749\n",
      "Epoch: 06 | Time: 1m 55s\n",
      "\tTrain Loss: 0.780 | Train PPL:   2.182\n",
      "\t Val. Loss: 3.139 |  Val. PPL:  23.089\n",
      "Epoch: 07 | Time: 2m 12s\n",
      "\tTrain Loss: 0.740 | Train PPL:   2.097\n",
      "\t Val. Loss: 2.410 |  Val. PPL:  11.130\n",
      "Epoch: 08 | Time: 2m 11s\n",
      "\tTrain Loss: 0.671 | Train PPL:   1.957\n",
      "\t Val. Loss: 2.946 |  Val. PPL:  19.030\n",
      "Epoch: 09 | Time: 2m 5s\n",
      "\tTrain Loss: 0.644 | Train PPL:   1.904\n",
      "\t Val. Loss: 3.043 |  Val. PPL:  20.976\n",
      "Epoch: 10 | Time: 1m 49s\n",
      "\tTrain Loss: 0.590 | Train PPL:   1.803\n",
      "\t Val. Loss: 3.009 |  Val. PPL:  20.265\n",
      "Epoch: 11 | Time: 1m 49s\n",
      "\tTrain Loss: 0.542 | Train PPL:   1.719\n",
      "\t Val. Loss: 2.954 |  Val. PPL:  19.185\n",
      "Epoch: 12 | Time: 1m 50s\n",
      "\tTrain Loss: 0.509 | Train PPL:   1.663\n",
      "\t Val. Loss: 2.898 |  Val. PPL:  18.143\n",
      "Epoch: 13 | Time: 1m 50s\n",
      "\tTrain Loss: 0.434 | Train PPL:   1.543\n",
      "\t Val. Loss: 2.879 |  Val. PPL:  17.800\n",
      "Epoch: 14 | Time: 1m 49s\n",
      "\tTrain Loss: 0.441 | Train PPL:   1.554\n",
      "\t Val. Loss: 2.031 |  Val. PPL:   7.624\n",
      "Epoch: 15 | Time: 1m 50s\n",
      "\tTrain Loss: 0.431 | Train PPL:   1.538\n",
      "\t Val. Loss: 2.575 |  Val. PPL:  13.127\n",
      "Epoch: 16 | Time: 1m 50s\n",
      "\tTrain Loss: 0.382 | Train PPL:   1.465\n",
      "\t Val. Loss: 2.484 |  Val. PPL:  11.987\n",
      "Epoch: 17 | Time: 1m 53s\n",
      "\tTrain Loss: 0.361 | Train PPL:   1.435\n",
      "\t Val. Loss: 2.020 |  Val. PPL:   7.537\n",
      "Epoch: 18 | Time: 1m 51s\n",
      "\tTrain Loss: 0.327 | Train PPL:   1.386\n",
      "\t Val. Loss: 2.166 |  Val. PPL:   8.726\n",
      "Epoch: 19 | Time: 1m 50s\n",
      "\tTrain Loss: 0.346 | Train PPL:   1.413\n",
      "\t Val. Loss: 1.880 |  Val. PPL:   6.557\n",
      "Epoch: 20 | Time: 1m 50s\n",
      "\tTrain Loss: 0.294 | Train PPL:   1.342\n",
      "\t Val. Loss: 1.825 |  Val. PPL:   6.204\n",
      "| Test Loss: 1.802 | Test PPL:   6.061 |\n"
     ]
    }
   ],
   "source": [
    "model_trained = model_execute(model, data, data, data,CRITERION,optimizer,clip_value = 1, n_epochs = 20,models_path = models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-immigration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hollywood-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence,model, vocab_nl,vocab_ql,nl_tokenizer,ql_tokenizer,device=DEVICE):\n",
    "    \n",
    "    BOS_IDX = vocab_nl['<bos>']\n",
    "    EOS_IDX = vocab_nl['<eos>']\n",
    "    \n",
    "    item = torch.tensor([vocab_nl[token] for token in nl_tokenizer(sentence)],\n",
    "                        dtype=torch.long)\n",
    "    input = torch.cat([torch.tensor([BOS_IDX]), item,\n",
    "                            torch.tensor([EOS_IDX])], dim=0).view(-1,1).to(device)\n",
    "    trg = torch.zeros(len(input)+10,dtype=torch.long).view(-1,1).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    output = model(input,trg,0)\n",
    "    output = output[1:].view(-1, output.shape[-1])\n",
    "    trg = trg[1:].view(-1)\n",
    "    print(output)\n",
    "    print(trg)\n",
    "\n",
    "#     translation = [vocab_ql.itos[index] for index in output]\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stainless-platinum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.9408, -3.6690, -3.8081,  ...,  6.3329,  5.2933,  4.9202],\n",
      "        [-4.2170, -3.9946, -4.1291,  ...,  6.2083,  5.1662,  4.7055],\n",
      "        [-4.1848, -3.9722, -4.0897,  ...,  6.1465,  4.7431,  4.4661],\n",
      "        ...,\n",
      "        [-4.7779, -4.7059, -4.7133,  ...,  6.0765,  5.1397,  5.8583],\n",
      "        [-4.6431, -4.5070, -4.5194,  ...,  6.1840,  4.6466,  5.8240],\n",
      "        [-5.1558, -4.9926, -5.0105,  ...,  5.8644,  3.6607,  5.4598]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "sent = \"where is unilever insurances n.v.\"\n",
    "out = translate(sent,model_trained,vocab_nl,vocab_ql,NL_TOKENIZER,QL_TOKENIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "similar-thinking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 395])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
<<<<<<< HEAD
   "id": "fuzzy-auction",
=======
   "id": "comparative-keyboard",
>>>>>>> 710f73201b0db08b166e19b2ea10de04eb0fac27
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9928, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.9447, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.3262, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.2805, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.6473, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.6826, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.7866, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.7347, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.1178, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.9178, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.5426, grad_fn=<MeanBackward0>)\n",
      "tensor(1.9392, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6401, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0615, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2097, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1501, grad_fn=<MeanBackward0>)\n",
      "tensor(-1.0392, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for row in out:\n",
    "    print(row.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
<<<<<<< HEAD
   "id": "automated-chocolate",
=======
   "id": "linear-maria",
>>>>>>> 710f73201b0db08b166e19b2ea10de04eb0fac27
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eiopa'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_ql.itos[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "atmospheric-reader",
=======
   "id": "statutory-carter",
>>>>>>> 710f73201b0db08b166e19b2ea10de04eb0fac27
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nqm_torch] *",
   "language": "python",
   "name": "conda-env-nqm_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
