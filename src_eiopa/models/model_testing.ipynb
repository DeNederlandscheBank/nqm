{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defined-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_data_loader,build_vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from baseline import init_model\n",
    "\n",
    "import os\n",
    "from os.path import join, exists\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import math\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-picking",
   "metadata": {},
   "source": [
    "## PARSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "solved-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choice = 'baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sixth-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_choice == 'baseline':\n",
    "    from baseline import init_model, train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "protected-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time: int,\n",
    "               end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "proper-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_execute(model,train_data,val_data,test_data,criterion,optimizer,clip_value, n_epochs,models_path):\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = train(model, train_data, optimizer, criterion, clip_value)\n",
    "        valid_loss = evaluate(model, val_data, criterion)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "\n",
    "    test_loss = evaluate(model, test_data, criterion)\n",
    "\n",
    "    print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')\n",
    "    \n",
    "    torch.save(model.state_dict(),join(models_path,\"model\" + time.strftime(\"_%d-%m_%H-%M\")))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "continent-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "NL_TOKENIZER = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "QL_TOKENIZER = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "resident-sculpture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required files exist!\n",
      "Model path exists!\n"
     ]
    }
   ],
   "source": [
    "data_path = join(\"..\",\"..\",\"data\",\"eiopa\",\"3_processed\")\n",
    "train_file_nl = join(data_path,\"data_baseline.nl\")\n",
    "train_file_ql = join(data_path,\"data_baseline.ql\")\n",
    "\n",
    "models_path = join(\"..\",\"..\",\"models\")\n",
    "\n",
    "if exists(train_file_nl) and exists(train_file_ql):\n",
    "    print(\"Required files exist!\")\n",
    "    \n",
    "if exists(models_path):\n",
    "    print(\"Model path exists!\")\n",
    "    \n",
    "vocab_nl = build_vocab(train_file_nl,NL_TOKENIZER)\n",
    "\n",
    "vocab_ql = build_vocab(train_file_ql,QL_TOKENIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "clear-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_data_loader(train_file_nl,train_file_ql,vocab_nl,vocab_ql,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pregnant-phone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized! \n",
      " The model has     205,203 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model,optimizer = init_model(DEVICE,len(vocab_nl),len(vocab_ql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "norwegian-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = vocab_ql.stoi['<pad>'] # for ouput language\n",
    "CRITERION = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "viral-rhythm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 30s\n",
      "\tTrain Loss: 4.825 | Train PPL: 124.544\n",
      "\t Val. Loss: 3.577 |  Val. PPL:  35.754\n",
      "Epoch: 02 | Time: 0m 29s\n",
      "\tTrain Loss: 3.522 | Train PPL:  33.837\n",
      "\t Val. Loss: 3.480 |  Val. PPL:  32.454\n",
      "Epoch: 03 | Time: 0m 30s\n",
      "\tTrain Loss: 3.303 | Train PPL:  27.195\n",
      "\t Val. Loss: 3.255 |  Val. PPL:  25.917\n",
      "Epoch: 04 | Time: 0m 32s\n",
      "\tTrain Loss: 2.892 | Train PPL:  18.024\n",
      "\t Val. Loss: 2.900 |  Val. PPL:  18.169\n",
      "Epoch: 05 | Time: 0m 30s\n",
      "\tTrain Loss: 2.380 | Train PPL:  10.809\n",
      "\t Val. Loss: 2.658 |  Val. PPL:  14.271\n",
      "Epoch: 06 | Time: 0m 30s\n",
      "\tTrain Loss: 1.893 | Train PPL:   6.640\n",
      "\t Val. Loss: 2.469 |  Val. PPL:  11.807\n",
      "Epoch: 07 | Time: 0m 33s\n",
      "\tTrain Loss: 1.577 | Train PPL:   4.839\n",
      "\t Val. Loss: 2.546 |  Val. PPL:  12.757\n",
      "Epoch: 08 | Time: 0m 30s\n",
      "\tTrain Loss: 1.361 | Train PPL:   3.899\n",
      "\t Val. Loss: 2.616 |  Val. PPL:  13.685\n",
      "Epoch: 09 | Time: 0m 29s\n",
      "\tTrain Loss: 1.251 | Train PPL:   3.492\n",
      "\t Val. Loss: 2.672 |  Val. PPL:  14.463\n",
      "Epoch: 10 | Time: 0m 30s\n",
      "\tTrain Loss: 1.109 | Train PPL:   3.032\n",
      "\t Val. Loss: 2.737 |  Val. PPL:  15.433\n",
      "Epoch: 11 | Time: 0m 32s\n",
      "\tTrain Loss: 1.030 | Train PPL:   2.802\n",
      "\t Val. Loss: 2.887 |  Val. PPL:  17.945\n",
      "Epoch: 12 | Time: 0m 32s\n",
      "\tTrain Loss: 1.011 | Train PPL:   2.749\n",
      "\t Val. Loss: 2.893 |  Val. PPL:  18.039\n",
      "Epoch: 13 | Time: 0m 30s\n",
      "\tTrain Loss: 0.938 | Train PPL:   2.555\n",
      "\t Val. Loss: 2.952 |  Val. PPL:  19.140\n",
      "Epoch: 14 | Time: 0m 30s\n",
      "\tTrain Loss: 0.871 | Train PPL:   2.390\n",
      "\t Val. Loss: 3.021 |  Val. PPL:  20.517\n",
      "Epoch: 15 | Time: 0m 30s\n",
      "\tTrain Loss: 0.830 | Train PPL:   2.292\n",
      "\t Val. Loss: 3.119 |  Val. PPL:  22.622\n",
      "Epoch: 16 | Time: 0m 30s\n",
      "\tTrain Loss: 0.814 | Train PPL:   2.258\n",
      "\t Val. Loss: 3.497 |  Val. PPL:  33.003\n",
      "Epoch: 17 | Time: 0m 30s\n",
      "\tTrain Loss: 0.785 | Train PPL:   2.192\n",
      "\t Val. Loss: 3.354 |  Val. PPL:  28.624\n",
      "Epoch: 18 | Time: 0m 32s\n",
      "\tTrain Loss: 0.757 | Train PPL:   2.132\n",
      "\t Val. Loss: 3.408 |  Val. PPL:  30.212\n",
      "Epoch: 19 | Time: 0m 30s\n",
      "\tTrain Loss: 0.748 | Train PPL:   2.113\n",
      "\t Val. Loss: 3.182 |  Val. PPL:  24.093\n",
      "Epoch: 20 | Time: 0m 33s\n",
      "\tTrain Loss: 0.685 | Train PPL:   1.984\n",
      "\t Val. Loss: 3.480 |  Val. PPL:  32.463\n",
      "| Test Loss: 3.476 | Test PPL:  32.336 |\n"
     ]
    }
   ],
   "source": [
    "model_trained = model_execute(model, data, data, data,CRITERION,optimizer,clip_value = 1, n_epochs = 20,models_path = models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-immigration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-things",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-platinum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "injured-sherman",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-thinking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nqm_torch] *",
   "language": "python",
   "name": "conda-env-nqm_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
