## Where the samples will be written
save_data: ../../data/processed
## Where the vocab(s) will be written
src_vocab: ../../data/processed.vocab.src
tgt_vocab: ../../data/processed.vocab.tgt


# Corpus opts:
data:
    corpus_1:
        path_src: ../../data/interim/train_en_shuff.txt
        path_tgt: ../../data/interim/train_sparql_shuf.txt
    valid:
        path_src: ../../data/interim/dev_en.txt
        path_tgt: ../../data/interim/dev_sparql.txt



# Where to save the checkpoints
save_model: ../../models/model
save_checkpoint_steps: 10000
train_steps: 10000
valid_steps: 1000

# # Batching
batch_size: 16
dropout: 0.1

# Optimization
optim: adam
learning_rate: 0.002
start_decay_steps: 1000
learning_rate_decay: 0.5

# Model
encoder_type: rnn
decoder_type: rnn
layers: 1
rnn_size: 100
word_vec_size: 100

# # attention
# copy_attn: 'true'
# global_attention: mlp
# reuse_copy_attn: 'true'
# bridge: 'true'
