{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiku_env = True\n",
    "try:\n",
    "    import dataiku\n",
    "except:\n",
    "    dataiku_env = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "import pandas as pd\n",
    "from rdflib.extras.external_graph_libs import rdflib_to_networkx_multidigraph\n",
    "import networkx as nx\n",
    "from networkx import Graph as NXGraph\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import isfile, join\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataiku_env:\n",
    "    handle = dataiku.Folder(\"taxonomies\")\n",
    "    taxonomy_file_path = handle.get_path() + \"/processed/\"\n",
    "    handle = dataiku.Folder(\"external\")\n",
    "    external_file_path = handle.get_path() + \"/\"\n",
    "    handle = dataiku.Folder(\"instances\")\n",
    "    instance_file_path = handle.get_path() + \"/real/processed/\"\n",
    "else:\n",
    "    taxonomy_file_path = join('..', 'data', 'rdf', 'xbrl', 'taxonomies')\n",
    "    instance_file_path = join('..', 'data', 'rdf', 'xbrl', 'instances')\n",
    "    external_eiopa_path = join('..', 'data', 'external', 'eiopa')\n",
    "    external_gleif_path = join('..', 'data', 'external', 'gleif')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load both the taxonomy and the instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = rdflib.Graph()\n",
    "\n",
    "taxonomy_files = ['schema_optimized.ttl']#,'linkbase2.ttl']\n",
    "for ttl_file in taxonomy_files:\n",
    "    with open(join(taxonomy_file_path, ttl_file), 'rb') as file:\n",
    "        g.parse(data=file.read(), format=\"turtle\")\n",
    "        print('added {} to graph g'.format(ttl_file))\n",
    "        \n",
    "instance_files = [f for f in listdir(instance_file_path) if (isfile(join(instance_file_path, f))) and f[-3:].lower()=='ttl']\n",
    "for ttl_file in instance_files:\n",
    "    with open(join(instance_file_path, ttl_file), 'rb') as file:\n",
    "        g.parse(data=file.read(), format=\"turtle\")\n",
    "        print('added {} to graph g'.format(ttl_file))\n",
    "    \n",
    "external_eiopa_files = [f for f in listdir(external_eiopa_path) if (isfile(join(external_eiopa_path, f))) and f[-3:].lower()=='ttl']\n",
    "for ttl_file in external_eiopa_files:\n",
    "    with open(join(external_eiopa_path, ttl_file), 'rb') as file:\n",
    "        g.parse(data=file.read(), format=\"turtle\")\n",
    "        print('added {} to graph g'.format(ttl_file))\n",
    "        \n",
    "external_gleif_files = [f for f in listdir(external_gleif_path) if (isfile(join(external_gleif_path, f))) and f[-3:].lower()=='ttl']\n",
    "for ttl_file in external_gleif_files:\n",
    "    with open(join(external_gleif_path, ttl_file), 'rb') as file:\n",
    "        g.parse(data=file.read(), format=\"turtle\")\n",
    "        print('added {} to graph g'.format(ttl_file))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"graph has {} statements.\".format(len(g)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a random context and make a new graph by slecting outwards from the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_part_graph(g, begin_triple, from_connections, to_connections):\n",
    "\n",
    "    \"\"\"\n",
    "    g:\n",
    "        the graph to explore\n",
    "    begin_triple:\n",
    "        the triple from which the graph is explored\n",
    "    from_connections :\n",
    "        is a list containing the max number of upstream nodes which should be explored \n",
    "    to_connections:\n",
    "        is a list containing the max number of downstream nodes which should be explored\n",
    "    \"\"\"\n",
    "\n",
    "    g_lite = rdflib.Graph()\n",
    "    \n",
    "    max_number_of_steps = len(from_connections)\n",
    "    if len(from_connections) != len(to_connections):\n",
    "        raise AssertionError('length of lists are not equal') \n",
    "    \n",
    "    previous_list = [begin_triple[0]]\n",
    "    for step in range(max_number_of_steps):\n",
    "        new_list = []\n",
    "        for triple_inst in previous_list:\n",
    "            total_list_down = list(g.triples((triple_inst, None, None)))\n",
    "            total_list_up = list(g.triples((None, None, triple_inst)))\n",
    "                        \n",
    "            for idx in range(min(from_connections[step],len(total_list_up))):\n",
    "                new_list.append(total_list_up[idx][0])\n",
    "                g_lite.add(total_list_up[idx])                           \n",
    "                \n",
    "            for idx in range(min(to_connections[step],len(total_list_down))):\n",
    "                new_list.append(total_list_down[idx][2])\n",
    "                g_lite.add(total_list_down[idx])                           \n",
    "                \n",
    "        previous_list = list(set(new_list))\n",
    "        \n",
    "    return g_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_a = list(g.triples((None, None, rdflib.term.URIRef('https://w3id.org/vocab/xbrll/Context'))))\n",
    "# list_a = list(g.triples((None, rdflib.term.URIRef('https://www.gleif.org/ontology/l1/LEI'), rdflib.term.Literal('72450051YQLIROHV2228'))))\n",
    "triple = list_a[26]\n",
    "g_lite = select_part_graph(g, triple, [0, 0, 0, 0, 0, 0, 0], [8, 8, 8, 8, 8, 8, 8])\n",
    "print(\"graph has {} statements.\".format(len(g_lite)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the graph to an networkx graph and define the edge and node labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nxgraph = rdflib_to_networkx_multidigraph(g_lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_labels = {}\n",
    "for edge in nxgraph.edges(keys=True, data=True):\n",
    "    edge_labels[edge[0],edge[1]] = str(edge[2]).split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels = {}\n",
    "for node in nxgraph.nodes:    \n",
    "    if isinstance(node, rdflib.term.URIRef):\n",
    "        node_labels[node] = str(node).split(\"/\")[-1].replace(\"instance\", \"\")\n",
    "    elif not isinstance(node, rdflib.term.BNode):\n",
    "        node_labels[node] = str(node).replace(\" \", \"\\n\")#[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=nxgraph.nodes(), columns=nxgraph.nodes())\n",
    "for row, data in nx.shortest_path_length(nxgraph):\n",
    "    for col, dist in data.items():\n",
    "        df.loc[row,col] = dist\n",
    "\n",
    "df = df.fillna(df.max().max())\n",
    "\n",
    "pos = nx.kamada_kawai_layout(nxgraph, dist=df.to_dict())\n",
    "#pos = nx.spring_layout(nxgraph)\n",
    "\n",
    "# Plot\n",
    "print(\"Visualizing the graph:\")\n",
    "\n",
    "plt.figure(1, figsize = (30, 20)) \n",
    "\n",
    "nx.draw_networkx_edge_labels(nxgraph, pos = pos, edge_labels = edge_labels, font_color='black', font_size = 10)\n",
    "nx.draw_networkx_labels(nxgraph, pos, labels = node_labels, font_size = 10)\n",
    "nx.draw(nxgraph, \n",
    "        pos,\n",
    "        edge_color = 'black', \n",
    "        with_labels = False, \n",
    "        node_color='black',\n",
    "        node_size = 3250, \n",
    "        arrowsize=40, \n",
    "        alpha= 0.1,\n",
    "        width= 1,\n",
    "        font_weight= 'regular')\n",
    "ax = plt.gca()\n",
    "ax.collections[0].set_edgecolor(\"#555555\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "creator": "M.Nijhuis",
  "customFields": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "tags": []
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
